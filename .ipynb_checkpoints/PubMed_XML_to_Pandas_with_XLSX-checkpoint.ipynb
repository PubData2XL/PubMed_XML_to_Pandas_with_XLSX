{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae86a95",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "081dd19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "#!python -m pip install --upgrade pip pandas jupyterthemes openpyxl xlsxwriter\n",
    "#!jt -t monokai -fs 12 -cellw 80% -T -N -kl\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pmids = \"12345678,24681012,1357911,11111111\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10cac3c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "45095d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def parse_date(pub_date, as_datetime=True):\n",
    "    if not pub_date:\n",
    "        pub_date = datetime.datetime.min\n",
    "    else:\n",
    "        time = \" 00:00:00\"\n",
    "        if \" \" in pub_date:\n",
    "            date = pub_date.split(\" \")\n",
    "            pub_date = date[0]\n",
    "            time = \" \" + date[1]\n",
    "        begin = \"^\"\n",
    "        end = \"$\"\n",
    "        YYYY = \"\\d{4}\"\n",
    "        MM_DD =\"\\d{2}\"\n",
    "        MM_ABRV = \"\\D+\"\n",
    "        divider = \"[\\s|-]{1}\"\n",
    "        YYYY_MM = begin + YYYY + divider + MM_DD + end\n",
    "        YYYY_ABRV = begin + YYYY + divider + MM_ABRV + end\n",
    "        YYYY_ABRV_DD = begin + YYYY + divider + MM_ABRV + divider + MM_DD + end\n",
    "        months = {\"[Jj][Aa][Nn].*\": \"01\", \"[Ff][Ee][Bb].*\": \"02\", \"[Mm][Aa][Rr].*\": \"03\",\n",
    "                  \"[Aa][Pp][Rr].*\": \"04\", \"[Mm][Aa][Yy].*\": \"05\", \"[Jj][Uu][Nn].*\": \"06\",\n",
    "                  \"[Jj][Uu][Ll].*\": \"07\", \"[Aa][Uu][Gg].*\": \"08\", \"[Ss][Ee][Pp].*\": \"09\",\n",
    "                  \"[Oo][Cc][Tt].*\": \"10\", \"[Nn][Oo][Vv].*\": \"11\", \"[Dd][Ee][Cc].*\": \"12\",\n",
    "                  \"[Ww][Ii][Nn].*\": \"12\", \"[Ss][Pp][Rr].*\": \"03\", \"[Ss][Uu][Mm].*\": \"06\",\n",
    "                  \"[Aa][Uu][Tt].*\": \"09\", \"[Ff][Aa][Ll].*\": \"09\"}\n",
    "        MM_DD_YYYY = begin + \"\\d{1,2}\\/{1}\\d{1,2}\\/{1}\\d{4}\" + end\n",
    "        ORDINAL_DATE = begin + \"\\d{5}\" + end\n",
    "        if re.search(begin + YYYY + end, pub_date): #2023\n",
    "            pub_date = pub_date + \"-01-01\"\n",
    "        elif re.search(YYYY_MM, pub_date): #2023-06\n",
    "            test = pub_date\n",
    "            pub_date = pub_date + \"-01\"\n",
    "        elif re.search(YYYY_ABRV, pub_date): #2023-Jun or 2023-Jun-23\n",
    "            for month_re, month_number in months.items():\n",
    "                YYYYMM_ABRV = begin + YYYY + divider + month_re + end\n",
    "                if re.search(YYYYMM_ABRV, pub_date):\n",
    "                    pub_date = pub_date[:4] + \"-\" + month_number + \"-01\"\n",
    "        elif re.search(YYYY_ABRV_DD, pub_date):\n",
    "            for month_re, month_number in months.items():\n",
    "                YYYYMM_ABRVDD = begin + YYYY + divider + month_re + divider + MM_DD + end\n",
    "                if re.search(YYYYMM_ABRVDD, pub_date):\n",
    "                    pub_date = pub_date[:4] + \"-\" + month_number + \"-\" + pub_date[-2:]\n",
    "        elif re.search(MM_DD_YYYY, pub_date): #\n",
    "            pub_date = pub_date.split(\"/\")\n",
    "            pub_date = pub_date[2] + \"-\" + pub_date[0] + \"-\" + pub_date[1]\n",
    "        elif re.search(ORDINAL_DATE, pub_date):\n",
    "            print(\"Ordinal date: \" + pub_date)\n",
    "            offset = datetime.datetime(1900, 1, 1)\n",
    "            pub_date = str((offset + datetime.timedelta(days=int(pub_date))).date())\n",
    "            #pub_date = str(datetime.date.fromordinal(int(pub_date)))\n",
    "            print(\"Ordinal date: \" + pub_date)\n",
    "        if as_datetime:\n",
    "            pub_date += time\n",
    "    return pub_date\n",
    "\n",
    "def get_journal_source(row):\n",
    "    source = \"\"\n",
    "    if row[\"ISOAbbreviation\"]:\n",
    "        ISOAbbreviation = row[\"ISOAbbreviation\"]\n",
    "        Original_PubDate = \" \".join(row[\"Original_PubDate\"].split(\"-\"))\n",
    "        Volume = row[\"Volume\"]\n",
    "        Issue = row[\"Issue\"]\n",
    "        Pagination = row[\"Pagination\"]\n",
    "        PubModel = row[\"PubModel\"]\n",
    "        doi = \"\"\n",
    "        pii = \"\"\n",
    "        ELocationID = row[\"ELocationID\"].strip(\"{\").strip(\"}\").split(\"||\")\n",
    "        for ELID in ELocationID:\n",
    "            if \"doi\" in ELID:\n",
    "                doi = ELID\n",
    "            if \"pii\" in ELID:\n",
    "                pii = ELID\n",
    "        DT_PubDate = row[\"PubDate\"]\n",
    "        DT_ArticleDate = row[\"ArticleDate_Electronic\"]\n",
    "        #DT_ArticleDate = pd.to_datetime(parse_pub_date(ArticleDate_Electronic)).dt.strftime('%Y-%m-%d')\n",
    "        #Methods Inf Med. 2012;51(3):189-98. doi: 10.3414/ME11-01-0055. Epub 2012 Apr 5.\n",
    "        source = str(ISOAbbreviation) + \".\" \n",
    "        #See: https://www.nlm.nih.gov/bsd/licensee/journal_source.html\n",
    "        if Original_PubDate and PubModel != \"Electronic-eCollection\":\n",
    "            source = source + \" \" + str(Original_PubDate)\n",
    "        elif Original_PubDate and PubModel == \"Electronic-eCollection\" and DT_ArticleDate:\n",
    "            try: #To remove trailing zero in Unix (Linux, OS X) use -\n",
    "                source = source + \" \" + DT_ArticleDate.strftime('%Y %b %-d')\n",
    "            except ValueError: #To remove trailing zero in Windows use #\n",
    "                source = source + \" \" + DT_ArticleDate.strftime('%Y %b %#d')\n",
    "        if Volume:\n",
    "            source = source + \";\" + str(Volume)\n",
    "        if Issue:\n",
    "            source = source + \"(\" + str(Issue) + \")\"\n",
    "        if Pagination:\n",
    "            source = source + \":\" + str(Pagination) + \".\"\n",
    "        elif pii:\n",
    "            source = source + \":\" + str(pii) + \".\"\n",
    "        if doi:\n",
    "            source = source + \" \" + str(doi) + \".\"\n",
    "        # See:  https://www.nlm.nih.gov/bsd/licensee/elements_descriptions.html#articledate\n",
    "        if DT_ArticleDate and (DT_ArticleDate < DT_PubDate) and PubModel != \"Electronic-eCollection\": #if articledate is older/lower than print day\n",
    "            try: #To remove trailing zero in Unix (Linux, OS X) use -\n",
    "                source = source + \" Epub \" + DT_ArticleDate.strftime('%Y %b %-d')\n",
    "            except ValueError: #To remove trailing zero in Windows use #\n",
    "                source = source + \" Epub \" + DT_ArticleDate.strftime('%Y %b %#d')\n",
    "        if PubModel == \"Electronic-eCollection\":\n",
    "            source = source + \" eCollection \" + Original_PubDate\n",
    "        if source:\n",
    "            source += \".\"\n",
    "    return source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a1746",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MEDLINE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&rettype=medline\"\n",
    "MEDLINE_URL += \"&api_key=YOUR_NCBI_KEY\"\n",
    "MEDLINE_URL += \"&retmode=xml&id=\" + pmids\n",
    "xslt_file = \"PubMed_XML_to_Pandas_Transformer.xsl\"\n",
    "df = pd.read_xml(MEDLINE_URL, xpath=\"/Citation\", stylesheet=xslt_file, dtype=str)\n",
    "df = df.fillna(value=\"\")\n",
    "\n",
    "date_columns = df.filter(like='Date').columns.to_list()\n",
    "for column in date_columns:\n",
    "    df[\"Original_\" + column] = df[column].copy()\n",
    "    df[column] = df[column].apply(lambda x: pd.to_datetime(parse_date(x, as_datetime=True), errors=\"coerce\"))\n",
    "\n",
    "df[\"Journal_Source\"] = df.apply(lambda x: get_journal_source(x), axis=1)\n",
    "df[\"DOI\"] = df[\"ELocationID\"].apply(lambda x: \"\".join([x.strip(\"doi: \") for x in x.split(\"||\") if \"doi\" in x]))\n",
    "df[\"PMC\"] = df[\"ArticleIdList\"].apply(lambda x: \"\".join([x.strip(\"pmc: \") for x in x.split(\"\\\\\") if \"pmc\" in x]))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47728b9",
   "metadata": {},
   "source": [
    "## Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062706b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "writer = pd.ExcelWriter(\"Transformed_PubMed_Data.xlsx\",\n",
    "                        engine=\"xlsxwriter\", \n",
    "                        datetime_format=\"yyyy-mm-dd hh:mm:ss\",\n",
    "                        date_format=\"yyyy-mm-dd\",)\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df.to_excel(writer, sheet_name=\"Data\", index=False, header=True)\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Data\"]\n",
    "(max_row, max_col) = df.shape\n",
    "worksheet.set_column(1, max_col, 20)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da46bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
